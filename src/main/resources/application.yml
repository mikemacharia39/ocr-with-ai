server:
  port: 5011

spring:
  application:
    name: ocr-with-ai
  ai:
    ollama:
      chat:
        options:
#          multimodal model use gemma3:4b
#          model: gemma3:4b
#          embeddings model use snowflake-arctic-embed:137m
#          model: snowflake-arctic-embed:137m
          model: tinyllama:1.1b
          temperature: 0.7 # The temperature of the model. Increasing the temperature will make the model answer more creatively.
          maxTokens: 2048  # Adjust max tokens for longer responses
    vectorstore:
      pgvector:
        initialize-schema: true
        schema-name:
  #        dimensions: 1024 # Adjust dimensions based on the model used
  datasource:
    url: jdbc:postgresql://localhost:5432/temperature_db
    username: mike
    password: s3cret

# For direct API calls to Ollama
ollama:
  api:
    url: http://localhost:11434


feign:
  client:
    config:
      default:
        connectTimeout: 5000
        readTimeout: 180000